# RTX 5070 Windows PC Optimized Configuration for Frame Generation Application

# Model Configuration - Optimized for RTX 5070
model:
  name: "FrameInterpolationNet"
  architecture: "optical_flow_based"  # Options: optical_flow_based, advanced
  input_channels: 3
  output_channels: 3
  hidden_dim: 512  # Increased for RTX 5070's 24GB VRAM
  num_layers: 6    # Deeper network for better quality
  dropout: 0.1

# Training Configuration - RTX 5070 Optimized
training:
  batch_size: 24  # Large batch size for RTX 5070 (24GB VRAM)
  learning_rate: 0.0008  # Slightly lower for stability with large batches
  num_epochs: 150
  validation_split: 0.15
  early_stopping_patience: 15
  save_interval: 3
  device: "cuda"
  gradient_accumulation_steps: 1
  warmup_epochs: 8
  weight_decay: 1e-4

# Data Configuration - High Resolution for RTX 5070
data:
  input_fps: 15  # Original video FPS
  target_fps: 60  # Target FPS after interpolation
  frame_size: [1024, 1024]  # High resolution for RTX 5070
  augmentation:
    enabled: true
    rotation_range: 15
    brightness_range: 0.3
    contrast_range: 0.3
    horizontal_flip: true
    gaussian_noise: 0.01  # Add noise for robustness
    color_jitter: true

# UCF101 Dataset Configuration
ucf101:
  enabled: true  # Enable UCF101 dataset
  interpolation_factor: 4  # Frames to generate between existing frames
  min_frames_per_video: 10  # Minimum frames per video
  download_from_huggingface: true  # Download from Hugging Face
  alternative_download: true  # Enable alternative download if HF fails
  train_ratio: 0.7  # Training set ratio
  val_ratio: 0.15   # Validation set ratio
  test_ratio: 0.15  # Test set ratio
  stratified_split: true  # Use stratified splitting by class
  quality_check: true  # Enable quality checks

# Paths
paths:
  data_dir: "data"
  models_dir: "models"
  logs_dir: "logs"
  output_dir: "output"
  train_data: "data/train"
  val_data: "data/validation"
  test_data: "data/test"

# Inference Configuration - RTX 5070 Optimized
inference:
  interpolation_factor: 4  # How many frames to generate between existing frames
  temporal_smoothing: true
  post_processing: true
  quality_threshold: 0.85
  batch_inference: true  # Process multiple frames at once
  memory_efficient: true  # Use memory efficient attention

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/frame_generation_rtx5070.log"

# Hardware Configuration - RTX 5070 Specific
hardware:
  num_workers: 12  # More workers for Windows PC
  pin_memory: true
  mixed_precision: true
  compile_model: true  # Enable PyTorch 2.0 compilation
  cuda_benchmark: true  # Enable CUDA benchmarking
  memory_efficient_attention: true
  tensor_parallel: false  # Single GPU setup
  gradient_checkpointing: true  # Save memory during training
  dataloader_pin_memory: true
  persistent_workers: true  # Keep workers alive between epochs

# RTX 5070 Specific Optimizations
rtx5070:
  enable_tf32: true  # Enable TensorFloat-32 for RTX 5070
  enable_cudnn_benchmark: true
  memory_fraction: 0.95  # Use 95% of GPU memory
  allow_growth: false
  enable_xla: false  # Disable XLA for better compatibility
  optimize_for_inference: true
